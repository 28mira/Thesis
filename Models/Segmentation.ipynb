{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b42855-f2fd-49c8-ad01-f3bb1c70675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from tensorflow.keras import models, layers, preprocessing, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import Compose, LoadImage, EnsureChannelFirst, ScaleIntensity, ToTensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6856c5a2-407c-4fae-afdd-cb0d52d49345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageGenerator():\n",
    "    input_folder = r'C:\\Users\\marto\\Desktop\\Szakdolgozat\\pogram\\brainTumor\\data'\n",
    "    output_folder = r'C:\\Users\\marto\\Desktop\\Szakdolgozat\\pogram\\brainTumor\\converted_data'\n",
    "    datas = []\n",
    "    img_size = (256,256)\n",
    "    for file_name in sorted(os.listdir(input_folder)):\n",
    "        if file_name.endswith('.mat'):\n",
    "            file_path = os.path.join(input_folder,file_name)\n",
    "            \n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                image = np.array(f['cjdata/image']).T\n",
    "                label = int(np.array(f['cjdata/label'])[0,0])\n",
    "    \n",
    "            image = image.astype(np.float64)\n",
    "            im_norm = 255*(image-image.min())/(image.max()-image.min())\n",
    "            im_uint8 = im_norm.astype(np.uint8)\n",
    "\n",
    "            file_name_base = os.path.splitext(file_name)[0]\n",
    "            output_file_path = os.path.join(output_folder,file_name_base + '.jpg')\n",
    "    \n",
    "            im_pil = Image.fromarray(im_uint8)\n",
    "            im_pil = im_pil.resize(img_size)\n",
    "            datas.append((np.array(im_pil,dtype=np.float32),label))\n",
    "            \n",
    "            im_pil.save(output_file_path)\n",
    "    #return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2de5cbfb-f5e5-4f91-8d8d-9f6334a124b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imageGeneratior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e85fa181-5d59-44d4-8bc2-4ffa548ae6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageProcesser():\n",
    "    input_folder = r'C:\\Users\\marto\\Desktop\\Szakdolgozat\\pogram\\brainTumor\\data'\n",
    "    datas = []\n",
    "    img_size = (256,256)\n",
    "    for file_name in sorted(os.listdir(input_folder)):\n",
    "        if file_name.endswith('.mat'):\n",
    "            file_path = os.path.join(input_folder,file_name)\n",
    "            \n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                label = int(np.array(f['cjdata/label'])[0,0])-1\n",
    "                image = np.array(f['cjdata/image']).T\n",
    "                tumor_border = np.array(f['cjdata/tumorBorder'])\n",
    "                tumor_mask = np.array(f['cjdata/tumorMask']).T\n",
    "                \n",
    "            eps = 1e-8\n",
    "            \n",
    "            image = image.astype(np.float64)\n",
    "            image = 255*(image-image.min())/(image.max()-image.min() + eps)\n",
    "            image = cv2.resize(image,img_size)\n",
    "            image_norm = image.astype(np.float32)/255.0\n",
    "            image = np.expand_dims(image_norm,axis=0)\n",
    "\n",
    "            tumor_mask = tumor_mask.astype(np.float64)\n",
    "            tumorMask = 255*(tumor_mask-tumor_mask.min())/(tumor_mask.max()-tumor_mask.min() + eps)\n",
    "            tumorMask = cv2.resize(tumorMask,img_size)\n",
    "            tumor_mask_norm = tumorMask.astype(np.float32)/255.0\n",
    "            mask = np.expand_dims(tumor_mask_norm,axis=0)\n",
    "\n",
    "            \n",
    "            datas.append((image,mask))\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7da0f57-03d7-4f1b-9c76-22a77d8a79cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = imageProcesser()\n",
    "X = datas[0]\n",
    "y = datas[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eab00d5-6eed-4e7c-8190-835821642798",
   "metadata": {},
   "outputs": [],
   "source": [
    "datageneration = preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20,       # forgatás (fokban)\n",
    "    width_shift_range=0.1,   # vízszintes eltolás\n",
    "    height_shift_range=0.1,  # függőleges eltolás\n",
    "    zoom_range=0.1,          # nagyítás/kicsinyítés\n",
    "    horizontal_flip=True,    # vízszintes tükrözés\n",
    "    fill_mode='nearest'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91addb20-6217-46d7-b843-c4a016d2de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/brats_segmentation_3d.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "752093cd-8e73-4a4a-bb9c-ec37874ef850",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8*len(datas))\n",
    "val_size = len(datas) - train_size\n",
    "train_datas, val_datas = torch.utils.data.random_split(datas,[train_size,val_size])\n",
    "\n",
    "train = DataLoader(train_datas,batch_size=8,shuffle=True)\n",
    "val = DataLoader(val_datas,batch_size=8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24f910c3-6da2-41ca-896a-309ff5a0fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,       \n",
    "    out_channels=1,      \n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "659e8a00-0cc3-4783-8fe3-97ffdcb5af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = DiceLoss(to_onehot_y=True, sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f79e93d7-d5cb-4027-9fc5-71e48b36dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "055c76fd-bc0d-48a4-9018-d3c26484f56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9561275457326286\n",
      "Epoch 2, Loss: 0.9419602126562634\n",
      "Epoch 3, Loss: 0.9308613626110437\n",
      "Epoch 4, Loss: 0.9210789836579115\n",
      "Epoch 5, Loss: 0.9121567362294524\n",
      "Epoch 6, Loss: 0.9028319930020683\n",
      "Epoch 7, Loss: 0.8931077377027331\n",
      "Epoch 8, Loss: 0.8837340594502925\n",
      "Epoch 9, Loss: 0.8732433441407518\n",
      "Epoch 10, Loss: 0.8611405860717599\n",
      "Epoch 11, Loss: 0.8459513507759144\n",
      "Epoch 12, Loss: 0.8287786303591651\n",
      "Epoch 13, Loss: 0.8100720179974062\n",
      "Epoch 14, Loss: 0.7882116347648421\n",
      "Epoch 15, Loss: 0.7523500414547004\n",
      "Epoch 16, Loss: 0.7194694080647894\n",
      "Epoch 17, Loss: 0.6882811058616017\n",
      "Epoch 18, Loss: 0.6572260359599458\n",
      "Epoch 19, Loss: 0.6251351575121429\n",
      "Epoch 20, Loss: 0.5951693163826722\n",
      "Epoch 21, Loss: 0.5697724899756403\n",
      "Epoch 22, Loss: 0.5381044614392694\n",
      "Epoch 23, Loss: 0.5072611624720819\n",
      "Epoch 24, Loss: 0.4784121952150078\n",
      "Epoch 25, Loss: 0.4503126313321365\n",
      "Epoch 26, Loss: 0.42461157854682846\n",
      "Epoch 27, Loss: 0.4016454966817694\n",
      "Epoch 28, Loss: 0.3783820208878005\n",
      "Epoch 29, Loss: 0.35519640734995617\n",
      "Epoch 30, Loss: 0.33196587564502555\n"
     ]
    }
   ],
   "source": [
    "loss_function = DiceLoss(sigmoid=True)\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, (images, masks) in enumerate(train):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce38b7d-906f-42b1-b234-9c28d4124ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906cf774-3810-4ece-9c32-1be23265947b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
